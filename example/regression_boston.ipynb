{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c6e929c-dabd-4262-aded-f0c1ad40c13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gpytorch\n",
    "import timm\n",
    "from adabelief_pytorch import AdaBelief"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "108198e8-361b-43e7-98bd-c23ad4839371",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"../\")\n",
    "from estimator import ssge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b73924bf-7f60-42e9-886a-22a54e245e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = ssge.SSGE(\n",
    "    gpytorch.kernels.ScaleKernel(\n",
    "        gpytorch.kernels.MaternKernel(\n",
    "            ard_num_dims = 10\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8835066-d5ad-4661-8e77-3865960c31e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = torch.distributions.multivariate_normal.MultivariateNormal(\n",
    "    torch.zeros(10),\n",
    "    torch.eye(10),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "5362439a-d54a-4c41-8473-95f8af122814",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nonconvexopt/.local/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this case special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows:\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and:\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "    \n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "data = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "eb893f51-ff4b-4c97-9c44-d896d9f8c754",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standarize(x):\n",
    "    return (x - x.mean(0, keepdims = True)) / x.std(0, keepdims = True)\n",
    "\n",
    "X = data['data']\n",
    "Y = data['target']\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state=5)\n",
    "X_train = standarize(torch.from_numpy(X_train)).to(torch.float32)\n",
    "Y_train = standarize(torch.from_numpy(Y_train)).to(torch.float32)\n",
    "X_test = standarize(torch.from_numpy(X_test)).to(torch.float32)\n",
    "Y_test = standarize(torch.from_numpy(Y_test)).to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "1f018919-08a0-4662-b1d6-8c3b404f6b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GP_prior(gpytorch.models.ExactGP):\n",
    "    def __init__(\n",
    "        self,\n",
    "        train_x: torch.Tensor,\n",
    "        train_y: torch.Tensor,\n",
    "        likelihood: gpytorch.likelihoods.Likelihood,\n",
    "    ):\n",
    "        super(GP_prior, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.cov_module = gpytorch.kernels.AdditiveKernel(\n",
    "            gpytorch.kernels.ScaleKernel(\n",
    "                gpytorch.kernels.MaternKernel(\n",
    "                    ard_num_dims = train_x.shape[-1]\n",
    "                )\n",
    "            ),\n",
    "            gpytorch.kernels.ScaleKernel(\n",
    "                gpytorch.kernels.PeriodicKernel(\n",
    "\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return gpytorch.distributions.MultivariateNormal(\n",
    "            self.mean_module(x),\n",
    "            self.cov_module(x),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "abb8e4e7-3cac-42c0-8613-15b4d9c9a9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "likelihood.train()\n",
    "model = GP_prior(\n",
    "    X_train,\n",
    "    Y_train,\n",
    "    likelihood\n",
    ")\n",
    "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "947d21cf-3e00-46d1-bd1a-cff3a607b84f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac64656b4c38479b9c44cccf309ec52f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "optimizer = torch.optim.LBFGS(model.parameters(), lr = 0.1)\n",
    "iterator = tqdm.notebook.tqdm(range(50))\n",
    "for ind in iterator:\n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "        loss = -mll(model(X_train), Y_train)\n",
    "        loss.backward()\n",
    "        return loss\n",
    "    loss = optimizer.step(closure)\n",
    "    iterator.set_postfix(loss=loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdadd560-a1c8-4dc4-b753-e97b537ab34d",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h3>Random inducing</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5933fedd-316a-49ca-a415-ab42d5c9fcbc",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h3>Adversarial inducing</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8548af8-fa50-4cfb-9e77-287be409d66f",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h3>Test input as inducing</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8100bf0a-164f-4a2f-ad96-217784d4ca0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([404, 13])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "525b46d2-1f54-4159-abf4-ea398deb7b91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([404])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ca9c106d-96b8-4d1d-9cbf-abd1c01eea0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ffn(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ffn, self).__init__()\n",
    "        self.l1 = nn.Linear(13, 50, bias = True)\n",
    "        self.l2 = nn.Linear(50, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.l1(x))\n",
    "        x = self.l2(x)\n",
    "        return x\n",
    "\n",
    "#net_fn = timm.create_model('mixer_b16_224', pretrained=True)\n",
    "net_fn = ffn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d5bf8d54-27b0-401d-8e9c-54d5292ad641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1 Linear(in_features=13, out_features=50, bias=True)\n",
      "l2 Linear(in_features=50, out_features=1, bias=True)\n"
     ]
    }
   ],
   "source": [
    "for name, module in net_fn.named_modules():\n",
    "    if isinstance(module, nn.Linear):\n",
    "        print(name, module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe8ebb2-6430-4e18-a3c3-97e069923ba4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
